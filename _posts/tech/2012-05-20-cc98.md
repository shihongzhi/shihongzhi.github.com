---
layout:     post
title:      抓取cc98的帖子
category: tech
description: 抓取cc98的帖子
tags: python, xhtml2pdf, BeautifulSoup, cc98
---

## 起因


这两天有点空，闲着无事。突然想到之前98行者无疆上面好像号召过同学把之前的帖子保存下来，以防98再次地震而导致文字或图片的丢失。觉得这件事很有意义，所以花了一点时间写了一个脚本，把精华帖和最近的好帖抓取下来做了这些pdf文件。格式是有点小乱，不过还过得去。也算是对论坛的一点小贡献吧 :)

## 技术


用python写小爬虫确实相当方便，像我这种python菜鸟花了一天多的时间就把这件事搞定了，可见python的强大

具体的细节是用`BeautifulSoup`来分析html结构，分析出需要的帖子内容及时间等信息。然后用`xhtml2pdf`转换成pdf保存。

中间遇到的最大困难就是分析帖子内容，由于cc98帖子的文字格式复杂，完全还原保存到pdf中比较繁琐，所以我直接filter掉了这些格式信息。所以pdf文档中的字体都是一样的

## 代码链接


抓取网页转换成pdf[代码](https://gist.github.com/2757811)

抓取网址[代码](https://gist.github.com/2757840)

cc98帖子[链接](http://www.cc98.org/dispbbs.asp?boardID=147&ID=3939213&page=)
