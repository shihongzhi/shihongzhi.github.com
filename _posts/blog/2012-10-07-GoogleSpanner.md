---
layout:     post
title:      Google Spanner学习笔记
category: blog
description: Google Spanner学习笔记
tags: 大规模, Spanner
---

最近初略的看了一下Google Spanner的论文，对大数据的研究才刚刚开始，下面是我的一些载录。有错误的话欢迎指正！

##两阶段提交协议

所谓两阶段为：
1. 请求阶段
2. 提交阶段

具体的过程如下面两图所示。
事务成功的情况：

![大鱼线]({{ BASE_PATH }}/images/5.gif)

事务回滚的情况：

![大鱼线]({{ BASE_PATH }}/images/6.gif)

个人觉得跟TCP的三次握手有点类似，主要也是要获得目标的响应状态。

##Paxos算法：

Paxos算法是Lamport提出的一种基于消息传递且具有高度容错特性的一致性算法。原论文用希腊城邦制定法律的神话故事来描述了这个复杂的过程，具体可以看[wiki](http://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95)上的choose value过程。

##Google Spanner：
Spanner是一个可扩展的，全球分布式的数据库。注意，它是一个数据库，而不是NoSQL，所以它对事务有很好的支持，并且对于在大范围内分布的多个副本数据具有较高的外部一致性保证。所以Spanner已经从一个类似BigTable的单一版本的Key-Value存储，演化成为一个具有时间属性的多版本的数据库。

作为一个全球分布式数据库，Spanner提供了几个有趣的特性：第一，在数据的副本配置方面，应用可以在一个很细的粒度上进行动态控制。第二，Spanner有两个重要的特性，即Spanner提供了读和写操作的外部一致性，以及在一个时间戳下面的跨越数据库的全球一致性的读操作。这些特性使得Spanner可以支持一致的备份、一致的MapReduce执行和原子模式变更，所有都是在全球范围内实现，即使存在正在处理中的事务也可以。

之所以能够提供这些特性的是Spanner可以为事务分配全球范围内有意义的提交时间戳，即使事务可能是分布式的。时间戳反映了事务序列化的顺序。实现这个特性的关键技术是TrueTime。

###TrueTime

TrueTime使用的时间是GPS和原子钟。TrueTime使用两种类型的时间，是因为它们有不同的失败模式。GPS的失败可能是接受失败，系统运行失败等。原子钟也会失效，不过失效的方式和GPS无关，不同原子钟之间的失效也没有彼此关联（GPS时间是依靠服务器接受得到的，所以是相互关联的）。不过由于存在频率误差，在经过很长的时间以后，原子钟都会产生明显误差。

TrueTime是由每个数据中心上面的许多time master机器和每台机器上的一个timeslave daemon来共同实现的。大多数master都有具备专用天线的GPS接收器，剩余的master（我们称为Armageddon master）则配备了原子钟。所有master的时间参考值都会进行彼此校对。每个master也会交叉检查时间参考值和本地时间的比值，如果二者差别太大，就会把自己驱逐出去。

Daemon会从许多master中收集投票，获得时间参考值，然后使用Marzullo算法的变种，来探测和拒绝欺骗，并且把本地时钟同步到非撒谎master的时间参考值

###实现

Spanner被组织成许多个zone的集合。一个zone包括一个zonemaster，和一百至几千个spanserver。Zonemaster把数据分配给spanserver，spanserver把数据提供给客户端。客户端使用每个zone上面的location proxy来定位可以为自己提供数据的spanserver。如下图所示：

![大鱼线]({{ BASE_PATH }}/images/7.jpg)

####Spanserver软件栈

与BigTable不同的是，Spanner会把时间戳分配给数据，这种非常重要的方式，使得Spanner更像一个多版本数据库，而不是一个键值存储。一个tablet的状态是存储在类似于B-树的文件集合和写前(write-ahead)的日志中，所有这些都会被保存到一个分布式的文件系统中，这个分布式文件系统被称为Colossus，它继承自GFS。

为了支持复制，每个spanserver会在每个tablet上面实现一个Paxos状态的机器。每个Paxos状态机器都会在相应的tablet中保存自己的元数据和日志。Paxos实现支持采用基于时间的领导者租约的长寿命的领导者。

对于每个是领导者的副本而言，每个spanserver会实现一个锁表来实现并发控制

每个spanserver也会实施一个事务管理器来支持分布式事务。这个事务管理器被用来实现一个participant leader，该组内的其他副本则是作为participant slaves。如果一个事务只包含一个Paxos组（对于许多事务而言都是如此），它就可以绕过事务管理器，因为锁表和Paxos二者一起可以保证事务性。如果一个事务包含了多于一个Paxos组，那些组的领导者之间会彼此协调合作完成两阶段提交。其中一个参与者组，会被选为协调者，该组的participant leader被称为coordinator leader，该组的participant slaves被称为coordinator slaves。

具体如下图所示：

![大鱼线]({{ BASE_PATH }}/images/8.jpeg)

####数据模型

Spanner实现支持一个被称为“目录”的桶抽象，也就是包含公共前缀的连续键的集合。一个目录是数据放置的基本单元。属于一个目录的所有数据，都具有相同的副本配置。当数据在不同的Paxos组之间进行移动时，会一个目录一个目录地转移。当然在实际过程中，移动是分片移动的，而不是整个目录移动的。如下图所示：

![大鱼线]({{ BASE_PATH }}/images/9.jpeg)

应用的数据模型是架构在被目录桶装的键值映射层之上。一个应用会在一个universe中创建一个或者多个数据库。每个数据库可以包含无限数量的模式化的表。每个表都和关系数据库表类似，具备行、列和版本值。 Spanner的数据模型不是纯粹关系型的，它的行必须有名称。更准确地说，每个表都需要有包含一个或多个主键列的排序集合。采用这种结构是很有用的，因为这可以让应用通过选择键来控制数据的局部性。

![大鱼线]({{ BASE_PATH }}/images/10.jpeg)

上图包含了一个Spanner模式的实例，它是以每个用户和每个相册为基础存储图片元数据。其中相册是继承与用户的表，在存储的过程中就形成了“目录”的特性，一个用户所包含的所有相册就构成一个目录。

###并发控制

Spanner可以支持读写事务、只读事务（预先声明的快照隔离事务）和快照读。独立写操作，会被当成读写事务来执行。非快照独立读操作，会被当成只读事务来执行。

一个只读事务具备**快照隔离**的性能优势。一个只读事务必须事先被声明不会包含任何写操作，它并不是一个简单的不包含写操作的读写事务。在一个只读事务中的读操作，在执行时会采用一个系统选择的时间戳，不包含锁机制，因此，后面到达的写操作不会被阻塞。在一个只读事务中的读操作，可以到任何足够新的副本上去执行（见第4.1.3节）。

一个快照读操作，是针对历史数据的读取，执行过程中，不需要锁机制。一个客户端可以为快照读确定一个时间戳，或者提供一个时间范围让Spanner来自动选择时间戳。不管是哪种情况，快照读操作都可以在任何具有足够新的副本上执行。

对于只读事务和快照读而言，一旦已经选定一个时间戳，那么，提交就是不可避免的，除非在那个时间点的数据已经被垃圾回收了。因此，客户端不必在retry loop中缓存结果。当一个服务器失效的时候，客户端就可以使用同样的时间戳和当前的读位置，在另外一个服务器上继续执行读操作。

###F1

F1后台最开始是基于MySQL数据库，在许多方面都采用手工数据分区。MySQL的数据分片机制，会把每个客户和所有相关的数据分配给一个固定的分区。这种布局方式，可以支持针对单个客户的索引构建和复杂查询处理。随着客户数量的增长，对数据进行重新分区，代价是很大的。文中提到最近一次的重新分区，花费了两年的时间！

Spanner相比于MySQL的优点为：首先，Spanner不需要手工分区。其次，Spanner提供了同步复制和自动失败恢复。再次，具有强壮的事务语义

##总结

最近虽然看了不少大规模数据处理方向相关的内容，但还是停留在了解感念的阶段。也没有在项目中真正从事过相关的工作，没有实践经验的支持。有理解错误的地方，希望大家指正！